{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import mobilenet_v2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import BatchNorm2d\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import os, shutil, glob\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
    "# мы будем игнорировать warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_encoder(file_name, encoder):\n",
    "    with open(file_name, 'wb') as le_dump_file:\n",
    "        pickle.dump(encoder, le_dump_file)\n",
    "    return\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode, encoder_file='label_encoder.pkl'):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "        self.len_ = len(self.files)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "            save_encoder(encoder_file, self.label_encoder)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "    \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x , dtype='float32') / 255.\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        w,h = image.size\n",
    "        img0 = image\n",
    "        if (w > h):\n",
    "            img0 = transforms.Pad((0,(w-h)//2,0,w-h-((w-h)//2)))(image)\n",
    "        elif (w < h):\n",
    "            img0 = transforms.Pad(((h-w)//2,0,h-w-((h-w)//2), 0))(image)\n",
    "        w,h = img0.size\n",
    "        if(w == RESCALE_SIZE and h == RESCALE_SIZE):\n",
    "            return img0\n",
    "        return transforms.Resize((RESCALE_SIZE, RESCALE_SIZE))(img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и делает рандом кроп с аугментацией\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode, encoder_file='label_encoder.pkl'):\n",
    "        super().__init__(files, mode, encoder_file)\n",
    "        return\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "\n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        #image.load()\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        hh = max(0, int(np.random.randn()*22.))\n",
    "        hh = hh if(hh*10 < RESCALE_SIZE) else 22\n",
    "        if(hh > 0):\n",
    "            x = transforms.RandomCrop((RESCALE_SIZE-hh,RESCALE_SIZE-hh))(x)\n",
    "            x = transforms.RandomApply((transforms.RandomHorizontalFlip(), \n",
    "                                        transforms.RandomAffine(degrees=75, scale=(0.7, 1.1), shear=0.2)), p=0.8)(x)\n",
    "            x = transforms.Resize((RESCALE_SIZE, RESCALE_SIZE))(x)\n",
    "        x = np.array(x, dtype='float32')/ 255.0\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import SGD\n",
    "from torchvision.models import mobilenet_v2\n",
    "matplotlib.style.use('ggplot')\n",
    "# создаем класс TrainClassifier для тренировки моделей на pytorch\n",
    "\n",
    "\n",
    "def __get_device__(): # получаем устройство\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def default_lr_schedule():\n",
    "    \"\"\"функция возвращает итератор с 320 значениями learning rate\"\"\"\n",
    "    lrs = [0.002/(1.+0.9*n) for n in np.arange(20)] # range(100)\n",
    "    lrs.extend([0.0002 - (0.0000005*k) for k in np.arange(300)])\n",
    "    return lrs.__iter__()\n",
    "\n",
    "    \n",
    "def mobilenetv2(n_outputs = 2):\n",
    "    simple_cnn = mobilenet_v2(pretrained=False)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.BatchNorm1d(1280),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn\n",
    "\n",
    "\n",
    "def original_mobilenetv2(n_outputs = 12):\n",
    "    simple_cnn = mobilenet_v2(pretrained=True)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn\n",
    "\n",
    "\n",
    "class TrainClassifier:\n",
    "    \n",
    "    def __init__(self, n_outputs, model:nn.Module = None, criterion = None, batch_size = 64):\n",
    "        self.device = __get_device__()\n",
    "        self.neuralnet = mobilenetv2(n_outputs).to(self.device) if model is None else model.to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss() if criterion is None else criterion\n",
    "        self.optimizer = torch.optim.Adam(self.neuralnet.parameters())\n",
    "        self.optimizer_generator = None\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = 100\n",
    "        self.finalizer = None\n",
    "        self.total_epochs = 0\n",
    "        self.history = []\n",
    "        return\n",
    "\n",
    "\n",
    "    def __optimizer_gen__(self, optimizer_type, lr_schedule):\n",
    "        self.lr = lr_schedule.__next__()\n",
    "        while self.lr is not None:\n",
    "            print('LR = ', self.lr)\n",
    "            yield torch.optim.Adam(self.neuralnet.parameters(), lr = self.lr) if(optimizer_type == 'adam') else torch.optim.SGD(self.neuralnet.parameters(), lr = lr)\n",
    "            self.lr = lr_schedule.__next__()\n",
    "        return\n",
    "\n",
    "\n",
    "    def __fit_once__(self, train_loader):\n",
    "        self.neuralnet.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        processed_data = 0\n",
    "        if (self.optimizer_generator is not None):\n",
    "            self.optimizer = self.optimizer_generator.__next__()\n",
    "        k = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.neuralnet(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            processed_data += inputs.size(0)\n",
    "            k += 1\n",
    "            if (k%500 == 0):\n",
    "                print(k)\n",
    "        loss = running_loss / processed_data\n",
    "        acc = running_corrects.cpu().numpy() / processed_data\n",
    "        self.total_epochs += 1\n",
    "        return loss, acc\n",
    "\n",
    "\n",
    "    def __eval_once__(self, val_loader):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        processed_size = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            self.neuralnet.eval()\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = self.neuralnet(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            processed_size += inputs.size(0)\n",
    "        loss = running_loss / processed_size\n",
    "        acc = running_corrects.double() / processed_size\n",
    "        return loss, acc.item()\n",
    "\n",
    "\n",
    "    def with_epochs(self, epochs, finalizer=None):\n",
    "        self.epochs = epochs\n",
    "        return self\n",
    "\n",
    "\n",
    "    def with_lr(self, lr, optimizer_type = 'adam'):\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.neuralnet.parameters(), lr=lr) if(optimizer_type == 'adam') else torch.optim.SGD(self.neuralnet.parameters(), lr=lr)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def with_optimizer(self, optimizer_type, lr_schedule = None):\n",
    "        if(lr_schedule is None):\n",
    "            self.optimizer = torch.optim.Adam(self.neuralnet.parameters()) if(optimizer_type == 'adam') else torch.optim.SGD(self.neuralnet.parameters())\n",
    "        else:\n",
    "            self.lr_schedule = lr_schedule\n",
    "            self.optimizer_generator = self.__optimizer_gen__(optimizer_type, lr_schedule)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def with_metrics(self, metric = 'acc'):\n",
    "        self.metric = 'acc'\n",
    "        return self\n",
    "\n",
    "\n",
    "    #supports only mathplotlib.pyplot\n",
    "    def with_graph(self, graph_type = 'loss_results'):\n",
    "        def draw_func(history):\n",
    "            if (len(history) == 0):\n",
    "                return\n",
    "            loss, res, val_loss, val_res = zip(*history)\n",
    "            plt.figure(figsize=(9, 7))\n",
    "            if (graph_type == 'results'):\n",
    "                plt.plot(res, label=\"train_acc\")\n",
    "                plt.plot(val_res, label=\"val_acc\")\n",
    "                plt.ylabel(\"acc\")\n",
    "            elif (graph_type == 'loss' or graph_type == 'loss_results'):\n",
    "                plt.plot(loss, label=\"train_loss\")\n",
    "                plt.plot(val_loss, label=\"val_loss\")\n",
    "                plt.ylabel(\"loss\")\n",
    "                if (graph_type == 'loss_results'):\n",
    "                    plt.legend(loc='best')\n",
    "                    plt.xlabel(\"epochs\")\n",
    "                    plt.show()\n",
    "                    plt.figure(figsize=(9, 7))\n",
    "                    plt.plot(res, label=\"train_acc\")\n",
    "                    plt.plot(val_res, label=\"val_acc\")\n",
    "                    plt.ylabel(\"acc\")\n",
    "            else:\n",
    "                return\n",
    "            plt.legend(loc='best')\n",
    "            plt.xlabel(\"epochs\")\n",
    "            plt.show()\n",
    "            return\n",
    "\n",
    "        self.draw_fn = draw_func\n",
    "        return self\n",
    "\n",
    "\n",
    "    #terminal operation\n",
    "    def fit(self, train_dataset, val_dataset, enable_tqdm=False):\n",
    "        end_results = []\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader =    DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        log_template = \"\\nEpoch {ep:03d} train loss: {t_loss:0.4f} valid loss {v_loss:0.4f} train acc {t_acc:0.4f} valid acc {v_acc:0.4f}\"\n",
    "        def display_results(train_loss, train_acc, val_loss, val_acc, epoch, pbar, log_template):\n",
    "            if (enable_tqdm):\n",
    "                pbar.update(1)\n",
    "                tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            else:\n",
    "                print(log_template.format(ep=epoch+1, t_loss=train_loss, v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "        \n",
    "        \n",
    "        def cycle(pbar):\n",
    "            for epoch in range(self.epochs):\n",
    "                train_loss, train_acc = self.__fit_once__(train_loader)\n",
    "                val_loss, val_acc = self.__eval_once__(val_loader)\n",
    "                end_results.append((train_loss, train_acc, val_loss, val_acc))\n",
    "                display_results(train_loss, train_acc, val_loss, val_acc, epoch, pbar, log_template)\n",
    "        \n",
    "\n",
    "        if (enable_tqdm):\n",
    "            with tqdm(desc=\"epoch\", total=self.epochs) as pbar:\n",
    "                cycle(pbar)\n",
    "        else:\n",
    "            cycle(None)\n",
    "        self.history.extend(end_results)\n",
    "        return end_results\n",
    "\n",
    "\n",
    "    def evaluate(self, val_dataset):    #terminal operation\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        return self.__eval_once__(val_loader)\n",
    "\n",
    "\n",
    "    def do_fit(self, train_dataset, val_dataset, enable_tqdm=False):\n",
    "        hist = self.fit(train_dataset, val_dataset, enable_tqdm)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def do_evaluate(self, val_dataset):\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        loss, acc = self.__eval_once__(val_loader)\n",
    "        print(\"evaluation loss/acc: \", loss, acc)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def display_history(self):    #terminal operation\n",
    "        if(self.draw_fn is not None):\n",
    "            self.draw_fn(self.history)\n",
    "        return\n",
    "    \n",
    "\n",
    "    def display_model(self):    #terminal operation\n",
    "        print(self.neuralnet)\n",
    "\n",
    "\n",
    "    def display_all(self, print_model = False):    #terminal operation\n",
    "        self.display_history()\n",
    "        if (print_model):\n",
    "            self.display_model()\n",
    "        return\n",
    "\n",
    "\n",
    "    def save_dict(self, name):\n",
    "        torch.save(self.neuralnet.state_dict(), name + '.dict')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Инициализируем датасеты \n",
    "# далее тренируем сеть на основе MobileNet v2\n",
    "# в течении 80 эпох постепенно уменьшая LR\n",
    "torch.manual_seed(17)\n",
    "np.random.seed(17)\n",
    "\n",
    "# скопировал картинки после работы preprocess_img.ipynb в каталог train\n",
    "# из всех картинок перенес с удалением в источнике по 30 картинок из каталогов 0 и 1 в testset\n",
    "TRAIN_DIR = Path('./train')\n",
    "# каталог для test set\n",
    "TEST_DIR = Path('./testset')\n",
    "\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n",
    "test_dataset = BaseDataset(test_files, mode=\"val\")\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "labels = [path.parent.name for path in train_val_files]\n",
    "\n",
    "#dataset\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.15, stratify=labels)\n",
    "train_dataset = TransformedDataset(train_files, mode='train')\n",
    "val_dataset = BaseDataset(val_files, mode='val')\n",
    "val_dataset_a = TransformedDataset(val_files, mode='val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = './mobilenetv2_80_'\n",
    "schedule = default_lr_schedule()\n",
    "# тренируем сеть на основе MobileNet v2 с количеством классов = 2 batch_size = 128\n",
    "# в течении 80 эпох постепенно уменьшая LR\n",
    "model = TrainClassifier(3, batch_size = 128)\n",
    "model.with_epochs(80).with_optimizer('adam', lr_schedule = schedule).with_graph()\n",
    "model.do_fit(train_dataset, val_dataset, enable_tqdm=True).display_all()\n",
    "# сохраняем словарь нейросети на диске\n",
    "model.save_dict(SAVE_DIR+'3_cl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем независимую проверку точности на тестовом датасете\n",
    "model.do_evaluate(test_dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для использования в чат-боте\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import mobilenet_v2\n",
    "MODEL = None\n",
    "RESCALE_SIZE = 224\n",
    "\n",
    "\n",
    "def get_model(n_outputs = 3):\n",
    "    simple_cnn = mobilenet_v2(pretrained=False)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.BatchNorm1d(1280),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn\n",
    "\n",
    "\n",
    "def load_state_dict(neuralnet, name):\n",
    "    neuralnet.load_state_dict(torch.load(name))\n",
    "    return neuralnet\n",
    "\n",
    "\n",
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "def get_image(img_name):\n",
    "    # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "    image = Image.open(img_name)\n",
    "    image.load()\n",
    "    x = np.array(image.resize((RESCALE_SIZE, RESCALE_SIZE)))\n",
    "    x = np.array(x / 255, dtype='float32')\n",
    "    x = transform(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# код для использования в чат-боте\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m mobilenetv2(n_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../model/mobilenetv2_80_3_cl.dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     13\u001b[0m MODEL \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     16\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../model/label_encoder.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(neuralnet, name)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_state_dict\u001b[39m(neuralnet, name):\n\u001b[0;32m---> 20\u001b[0m     neuralnet\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m neuralnet\n",
      "File \u001b[0;32m/home/bin/anaconda/lib/python3.9/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/bin/anaconda/lib/python3.9/site-packages/torch/serialization.py:930\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    928\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    929\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 930\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    934\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/bin/anaconda/lib/python3.9/site-packages/torch/serialization.py:876\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    872\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m--> 876\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    877\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    879\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/bin/anaconda/lib/python3.9/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/home/bin/anaconda/lib/python3.9/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/home/bin/anaconda/lib/python3.9/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "def mobilenetv2(n_outputs = 2):\n",
    "    simple_cnn = mobilenet_v2(pretrained=False)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.BatchNorm1d(1280),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn.cpu()\n",
    "\n",
    "# код для использования в чат-боте\n",
    "\n",
    "model = mobilenetv2(n_outputs = 3)\n",
    "load_state_dict(model, '../model/mobilenetv2_80_3_cl.dict').cpu()\n",
    "MODEL = model\n",
    "\n",
    "\n",
    "label_encoder = pickle.load(open(\"../model/label_encoder.pkl\", 'rb'))\n",
    "img = get_image('./yama.jpg')\n",
    "prob_pred = predict_one_sample(MODEL, img[None,...])\n",
    "print(prob_pred)\n",
    "y_pred = np.argmax(prob_pred)\n",
    "predicted_label = label_encoder.classes_[y_pred]\n",
    "print(predicted_label, 'asphalt' if predicted_label == '0' else 'defect' if predicted_label == '1' else 'latch')\n",
    "img = get_image('./none.jpg')\n",
    "prob_pred = predict_one_sample(MODEL, img[None,...])\n",
    "y_pred = np.argmax(prob_pred)\n",
    "predicted_label = label_encoder.classes_[y_pred]\n",
    "print(predicted_label, 'asphalt' if predicted_label == '0' else 'defect' if predicted_label == '1' else 'latch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
