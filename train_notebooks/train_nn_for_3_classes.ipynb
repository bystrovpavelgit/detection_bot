{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import mobilenet_v2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.nn import BatchNorm2d\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import os, shutil, glob\n",
    "from shutil import copyfile\n",
    "import pandas as pd\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
    "# мы будем игнорировать warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_encoder(file_name, encoder):\n",
    "    with open(file_name, 'wb') as le_dump_file:\n",
    "        pickle.dump(encoder, le_dump_file)\n",
    "    return\n",
    "\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode, encoder_file='label_encoder.pkl'):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "        self.len_ = len(self.files)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "            save_encoder(encoder_file, self.label_encoder)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "    \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        x = self._prepare_sample(x)\n",
    "        x = np.array(x , dtype='float32') / 255.\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        w,h = image.size\n",
    "        img0 = image\n",
    "        if (w > h):\n",
    "            img0 = transforms.Pad((0,(w-h)//2,0,w-h-((w-h)//2)))(image)\n",
    "        elif (w < h):\n",
    "            img0 = transforms.Pad(((h-w)//2,0,h-w-((h-w)//2), 0))(image)\n",
    "        w,h = img0.size\n",
    "        if(w == RESCALE_SIZE and h == RESCALE_SIZE):\n",
    "            return img0\n",
    "        return transforms.Resize((RESCALE_SIZE, RESCALE_SIZE))(img0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и делает рандом кроп с аугментацией\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode, encoder_file='label_encoder.pkl'):\n",
    "        super().__init__(files, mode, encoder_file)\n",
    "        return\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "\n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        #image.load()\n",
    "        return image\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "        x = self.load_sample(self.files[index])\n",
    "        hh = max(0, int(np.random.randn()*22.))\n",
    "        hh = hh if(hh*10 < RESCALE_SIZE) else 22\n",
    "        if(hh > 0):\n",
    "            x = transforms.RandomCrop((RESCALE_SIZE-hh,RESCALE_SIZE-hh))(x)\n",
    "            x = transforms.RandomApply((transforms.RandomHorizontalFlip(), \n",
    "                                        transforms.RandomAffine(degrees=75, scale=(0.7, 1.1), shear=0.2)), p=0.8)(x)\n",
    "            x = transforms.Resize((RESCALE_SIZE, RESCALE_SIZE))(x)\n",
    "        x = np.array(x, dtype='float32')/ 255.0\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from torch.optim import SGD\n",
    "from torchvision.models import mobilenet_v2\n",
    "matplotlib.style.use('ggplot')\n",
    "# создаем класс TrainClassifier для тренировки моделей на pytorch\n",
    "\n",
    "\n",
    "def __get_device__(): # получаем устройство\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def default_lr_schedule():\n",
    "    \"\"\"функция возвращает итератор с 320 значениями learning rate\"\"\"\n",
    "    lrs = [0.002/(1.+0.9*n) for n in np.arange(20)] # range(100)\n",
    "    lrs.extend([0.0002 - (0.0000005*k) for k in np.arange(300)])\n",
    "    return lrs.__iter__()\n",
    "\n",
    "    \n",
    "def mobilenetv2(n_outputs = 2):\n",
    "    simple_cnn = mobilenet_v2(pretrained=False)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.BatchNorm1d(1280),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn\n",
    "\n",
    "\n",
    "def original_mobilenetv2(n_outputs = 12):\n",
    "    simple_cnn = mobilenet_v2(pretrained=True)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn\n",
    "\n",
    "\n",
    "class TrainClassifier:\n",
    "    \n",
    "    def __init__(self, n_outputs, model:nn.Module = None, criterion = None, batch_size = 64):\n",
    "        self.device = __get_device__()\n",
    "        self.neuralnet = mobilenetv2(n_outputs).to(self.device) if model is None else model.to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss() if criterion is None else criterion\n",
    "        self.optimizer = torch.optim.Adam(self.neuralnet.parameters())\n",
    "        self.optimizer_generator = None\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = 100\n",
    "        self.finalizer = None\n",
    "        self.total_epochs = 0\n",
    "        self.history = []\n",
    "        return\n",
    "\n",
    "\n",
    "    def __optimizer_gen__(self, optimizer_type, lr_schedule):\n",
    "        self.lr = lr_schedule.__next__()\n",
    "        while self.lr is not None:\n",
    "            print('LR = ', self.lr)\n",
    "            yield torch.optim.Adam(self.neuralnet.parameters(), lr = self.lr) if(optimizer_type == 'adam') else torch.optim.SGD(self.neuralnet.parameters(), lr = lr)\n",
    "            self.lr = lr_schedule.__next__()\n",
    "        return\n",
    "\n",
    "\n",
    "    def __fit_once__(self, train_loader):\n",
    "        self.neuralnet.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        processed_data = 0\n",
    "        if (self.optimizer_generator is not None):\n",
    "            self.optimizer = self.optimizer_generator.__next__()\n",
    "        k = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.neuralnet(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            preds = torch.argmax(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            processed_data += inputs.size(0)\n",
    "            k += 1\n",
    "            if (k%500 == 0):\n",
    "                print(k)\n",
    "        loss = running_loss / processed_data\n",
    "        acc = running_corrects.cpu().numpy() / processed_data\n",
    "        self.total_epochs += 1\n",
    "        return loss, acc\n",
    "\n",
    "\n",
    "    def __eval_once__(self, val_loader):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        processed_size = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            self.neuralnet.eval()\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = self.neuralnet(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                preds = torch.argmax(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            processed_size += inputs.size(0)\n",
    "        loss = running_loss / processed_size\n",
    "        acc = running_corrects.double() / processed_size\n",
    "        return loss, acc.item()\n",
    "\n",
    "\n",
    "    def with_epochs(self, epochs, finalizer=None):\n",
    "        self.epochs = epochs\n",
    "        return self\n",
    "\n",
    "\n",
    "    def with_lr(self, lr, optimizer_type = 'adam'):\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.neuralnet.parameters(), lr=lr) if(optimizer_type == 'adam') else torch.optim.SGD(self.neuralnet.parameters(), lr=lr)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def with_optimizer(self, optimizer_type, lr_schedule = None):\n",
    "        if(lr_schedule is None):\n",
    "            self.optimizer = torch.optim.Adam(self.neuralnet.parameters()) if(optimizer_type == 'adam') else torch.optim.SGD(self.neuralnet.parameters())\n",
    "        else:\n",
    "            self.lr_schedule = lr_schedule\n",
    "            self.optimizer_generator = self.__optimizer_gen__(optimizer_type, lr_schedule)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def with_metrics(self, metric = 'acc'):\n",
    "        self.metric = 'acc'\n",
    "        return self\n",
    "\n",
    "\n",
    "    #supports only mathplotlib.pyplot\n",
    "    def with_graph(self, graph_type = 'loss_results'):\n",
    "        def draw_func(history):\n",
    "            if (len(history) == 0):\n",
    "                return\n",
    "            loss, res, val_loss, val_res = zip(*history)\n",
    "            plt.figure(figsize=(9, 7))\n",
    "            if (graph_type == 'results'):\n",
    "                plt.plot(res, label=\"train_acc\")\n",
    "                plt.plot(val_res, label=\"val_acc\")\n",
    "                plt.ylabel(\"acc\")\n",
    "            elif (graph_type == 'loss' or graph_type == 'loss_results'):\n",
    "                plt.plot(loss, label=\"train_loss\")\n",
    "                plt.plot(val_loss, label=\"val_loss\")\n",
    "                plt.ylabel(\"loss\")\n",
    "                if (graph_type == 'loss_results'):\n",
    "                    plt.legend(loc='best')\n",
    "                    plt.xlabel(\"epochs\")\n",
    "                    plt.show()\n",
    "                    plt.figure(figsize=(9, 7))\n",
    "                    plt.plot(res, label=\"train_acc\")\n",
    "                    plt.plot(val_res, label=\"val_acc\")\n",
    "                    plt.ylabel(\"acc\")\n",
    "            else:\n",
    "                return\n",
    "            plt.legend(loc='best')\n",
    "            plt.xlabel(\"epochs\")\n",
    "            plt.show()\n",
    "            return\n",
    "\n",
    "        self.draw_fn = draw_func\n",
    "        return self\n",
    "\n",
    "\n",
    "    #terminal operation\n",
    "    def fit(self, train_dataset, val_dataset, enable_tqdm=False):\n",
    "        end_results = []\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader =    DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        log_template = \"\\nEpoch {ep:03d} train loss: {t_loss:0.4f} valid loss {v_loss:0.4f} train acc {t_acc:0.4f} valid acc {v_acc:0.4f}\"\n",
    "        def display_results(train_loss, train_acc, val_loss, val_acc, epoch, pbar, log_template):\n",
    "            if (enable_tqdm):\n",
    "                pbar.update(1)\n",
    "                tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "            else:\n",
    "                print(log_template.format(ep=epoch+1, t_loss=train_loss, v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
    "        \n",
    "        \n",
    "        def cycle(pbar):\n",
    "            for epoch in range(self.epochs):\n",
    "                train_loss, train_acc = self.__fit_once__(train_loader)\n",
    "                val_loss, val_acc = self.__eval_once__(val_loader)\n",
    "                end_results.append((train_loss, train_acc, val_loss, val_acc))\n",
    "                display_results(train_loss, train_acc, val_loss, val_acc, epoch, pbar, log_template)\n",
    "        \n",
    "\n",
    "        if (enable_tqdm):\n",
    "            with tqdm(desc=\"epoch\", total=self.epochs) as pbar:\n",
    "                cycle(pbar)\n",
    "        else:\n",
    "            cycle(None)\n",
    "        self.history.extend(end_results)\n",
    "        return end_results\n",
    "\n",
    "\n",
    "    def evaluate(self, val_dataset):    #terminal operation\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        return self.__eval_once__(val_loader)\n",
    "\n",
    "\n",
    "    def do_fit(self, train_dataset, val_dataset, enable_tqdm=False):\n",
    "        hist = self.fit(train_dataset, val_dataset, enable_tqdm)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def do_evaluate(self, val_dataset):\n",
    "        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "        loss, acc = self.__eval_once__(val_loader)\n",
    "        print(\"evaluation loss/acc: \", loss, acc)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def display_history(self):    #terminal operation\n",
    "        if(self.draw_fn is not None):\n",
    "            self.draw_fn(self.history)\n",
    "        return\n",
    "    \n",
    "\n",
    "    def display_model(self):    #terminal operation\n",
    "        print(self.neuralnet)\n",
    "\n",
    "\n",
    "    def display_all(self, print_model = False):    #terminal operation\n",
    "        self.display_history()\n",
    "        if (print_model):\n",
    "            self.display_model()\n",
    "        return\n",
    "\n",
    "\n",
    "    def save_dict(self, name):\n",
    "        torch.save(self.neuralnet.state_dict(), name + '.dict')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Инициализируем датасеты \n",
    "# далее тренируем сеть на основе MobileNet v2\n",
    "# в течении 80 эпох постепенно уменьшая LR\n",
    "torch.manual_seed(17)\n",
    "np.random.seed(17)\n",
    "\n",
    "# скопировал картинки после работы preprocess_img.ipynb в каталог train\n",
    "# из всех картинок перенес с удалением в источнике по 30 картинок из каталогов 0 и 1 в testset\n",
    "TRAIN_DIR = Path('./train')\n",
    "# каталог для test set\n",
    "TEST_DIR = Path('./testset')\n",
    "\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))\n",
    "test_dataset = BaseDataset(test_files, mode=\"val\")\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "labels = [path.parent.name for path in train_val_files]\n",
    "\n",
    "#dataset\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.15, stratify=labels)\n",
    "train_dataset = TransformedDataset(train_files, mode='train')\n",
    "val_dataset = BaseDataset(val_files, mode='val')\n",
    "val_dataset_a = TransformedDataset(val_files, mode='val')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = './mobilenetv2_80_'\n",
    "schedule = default_lr_schedule()\n",
    "# тренируем сеть на основе MobileNet v2 с количеством классов = 2 batch_size = 128\n",
    "# в течении 80 эпох постепенно уменьшая LR\n",
    "model = TrainClassifier(3, batch_size = 128)\n",
    "model.with_epochs(80).with_optimizer('adam', lr_schedule = schedule).with_graph()\n",
    "model.do_fit(train_dataset, val_dataset, enable_tqdm=True).display_all()\n",
    "# сохраняем словарь нейросети на диске\n",
    "model.save_dict(SAVE_DIR+'3_cl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем независимую проверку точности на тестовом датасете\n",
    "model.do_evaluate(test_dataset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для использования в чат-боте\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import mobilenet_v2\n",
    "MODEL = None\n",
    "RESCALE_SIZE = 224\n",
    "\n",
    "\n",
    "def get_model(n_outputs = 3):\n",
    "    simple_cnn = mobilenet_v2(pretrained=False)\n",
    "    simple_cnn.classifier = nn.Sequential(\n",
    "        nn.Dropout(0.2),\n",
    "        nn.BatchNorm1d(1280),\n",
    "        nn.Linear(1280, n_outputs, bias=True))\n",
    "    return simple_cnn\n",
    "\n",
    "\n",
    "def load_state_dict(neuralnet, name):\n",
    "    neuralnet.load_state_dict(torch.load(name))\n",
    "    return neuralnet\n",
    "\n",
    "\n",
    "def predict_one_sample(model, inputs, device=DEVICE):\n",
    "    \"\"\"Предсказание, для одной картинки\"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logit = model(inputs).cpu()\n",
    "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
    "    return probs\n",
    "\n",
    "\n",
    "def get_image(img_name):\n",
    "    # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "    image = Image.open(img_name)\n",
    "    image.load()\n",
    "    x = np.array(image.resize((RESCALE_SIZE, RESCALE_SIZE)))\n",
    "    x = np.array(x / 255, dtype='float32')\n",
    "    x = transform(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.284495e-11 1.000000e+00 6.026907e-23]]\n",
      "1 defect\n",
      "0 asphalt\n"
     ]
    }
   ],
   "source": [
    "# код для использования в чат-боте\n",
    "if MODEL is None:\n",
    "    model = mobilenetv2(n_outputs = 3)\n",
    "    load_state_dict(model, './mobilenetv2_80_3_cl.dict')\n",
    "    MODEL = model\n",
    "    \n",
    "\n",
    "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
    "img = get_image('./yama.jpg')\n",
    "prob_pred = predict_one_sample(MODEL, img[None,...])\n",
    "print(prob_pred)\n",
    "y_pred = np.argmax(prob_pred)\n",
    "predicted_label = label_encoder.classes_[y_pred]\n",
    "print(predicted_label, 'asphalt' if predicted_label == '0' else 'defect' if predicted_label == '1' else 'latch')\n",
    "img = get_image('./none.jpg')\n",
    "prob_pred = predict_one_sample(MODEL, img[None,...])\n",
    "y_pred = np.argmax(prob_pred)\n",
    "predicted_label = label_encoder.classes_[y_pred]\n",
    "print(predicted_label, 'asphalt' if predicted_label == '0' else 'defect' if predicted_label == '1' else 'latch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
